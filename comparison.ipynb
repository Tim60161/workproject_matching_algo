{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from services.ResumeInfoExtraction import ResumeInfoExtraction\n",
    "from services.JobInfoExtraction import JobInfoExtraction\n",
    "from source.schemas.resumeextracted import ResumeExtractedModel # Let's reintroduce later on\n",
    "from source.schemas.jobextracted import JobExtractedModel # Let's reintroduce later on\n",
    "from pypdf import PdfReader\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "#import openai\n",
    "import warnings \n",
    "import logging\n",
    "import os\n",
    "logging.getLogger('pypdf').setLevel(logging.ERROR)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Get the absolute path of the root directory\n",
    "ROOT_DIR = (\".\")\n",
    "\n",
    "# Paths to your pattern files\n",
    "degrees_patterns_path = os.path.join(ROOT_DIR, 'Resources', 'data', 'degrees.jsonl')\n",
    "majors_patterns_path = os.path.join(ROOT_DIR,  'Resources', 'data', 'majors.jsonl')\n",
    "skills_patterns_path = os.path.join(ROOT_DIR, 'Resources', 'data', 'skills.jsonl')\n",
    "\n",
    "\n",
    "\n",
    "def get_resumes(directory):\n",
    "    \n",
    "    def extract_pdf(path):\n",
    "        reader = PdfReader(path)\n",
    "        number_of_pages = len(reader.pages)\n",
    "        text = \"\"\n",
    "        for i in range(number_of_pages):\n",
    "            page = reader.pages[i]\n",
    "            text += page.extract_text()\n",
    "        return text\n",
    "    \n",
    "    dic = {}\n",
    "    \n",
    "    # Iterate over all files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        \n",
    "        if os.path.isfile(file_path) and filename.endswith(\".pdf\"):\n",
    "            name = filename.strip(\".pdf\")\n",
    "            resume_text = extract_pdf(file_path)\n",
    "            dic[name] = [resume_text]\n",
    "    \n",
    "    df = pd.DataFrame(dic).T\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={\"index\": \"name\", 0:\"raw\"}, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def resume_extraction(resumes):\n",
    "    resumes = resumes.copy()\n",
    "    names = resumes[[\"name\"]]\n",
    "    resume_extraction = ResumeInfoExtraction(skills_patterns_path, majors_patterns_path, degrees_patterns_path, resumes, names)\n",
    "    resumes_df = resume_extraction.extract_entities(resumes)\n",
    "    return resumes_df\n",
    "\n",
    "\n",
    "def job_info_extraction(jobs):\n",
    "    jobs = jobs.copy()\n",
    "    job_extraction = JobInfoExtraction(skills_patterns_path, majors_patterns_path, degrees_patterns_path, jobs)\n",
    "    job_df = job_extraction.extract_entities(jobs)\n",
    "    return job_df\n",
    "\n",
    "\n",
    "def calc_similarity(applicant_df, job_df):\n",
    "    \"\"\"\"Calculate cosine simlarity based on BERT embeddings of skills\"\"\"\n",
    "\n",
    "    def semantic_similarity_sbert_base_v2(job,resume):\n",
    "        \"\"\"calculate similarity with SBERT all-mpnet-base-v2\"\"\"\n",
    "        model = SentenceTransformer('all-mpnet-base-v2')\n",
    "        model.eval()\n",
    "        #Encoding:\n",
    "        score = 0\n",
    "        sen = job+resume\n",
    "        sen_embeddings = model.encode(sen)\n",
    "        for i in range(len(job)):\n",
    "            if job[i] in resume:\n",
    "                score += 1\n",
    "            else:\n",
    "                max_cosine_sim = max(cosine_similarity([sen_embeddings[i]],sen_embeddings[len(job):])[0]) \n",
    "                if max_cosine_sim >= 0.4:\n",
    "                    score += max_cosine_sim\n",
    "        score = score/len(job)  \n",
    "        return round(score,3)\n",
    "    \n",
    "    columns = ['applicant', 'job_id', 'all-mpnet-base-v2_score']\n",
    "    matching_dataframe = pd.DataFrame(columns=columns)\n",
    "    \n",
    "    for job_index in range(job_df.shape[0]):\n",
    "        columns = ['applicant', 'job_id', 'all-mpnet-base-v2_score']\n",
    "        matching_dataframe = pd.DataFrame(columns=columns)\n",
    "        ranking_dataframe = pd.DataFrame(columns=columns)\n",
    "        \n",
    "        matching_data = []\n",
    "        \n",
    "        for applicant_id in range(applicant_df.shape[0]):\n",
    "            matching_dataframe_job = {\n",
    "                \"applicant\": applicant_df.iloc[applicant_id, 0],\n",
    "                \"job_id\": job_index,\n",
    "                \"all-mpnet-base-v2_score\": semantic_similarity_sbert_base_v2(job_df['Skills'][job_index], applicant_df['Skills'][applicant_id])\n",
    "            }\n",
    "            matching_data.append(matching_dataframe_job)\n",
    "        \n",
    "        matching_dataframe = pd.concat([matching_dataframe, pd.DataFrame(matching_data)], ignore_index=True)\n",
    "    matching_dataframe['rank'] = matching_dataframe['all-mpnet-base-v2_score'].rank(ascending=False)\n",
    "    return matching_dataframe\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create DataFrame for resumes\n",
    "    df_resumes = get_resumes(\"resumes\")\n",
    "    df_resumes = resume_extraction(df_resumes)\n",
    "    # print(df_resumes[[\"name\", \"Skills\"]])\n",
    "\n",
    "    # Create DataFrame for jobs\n",
    "    description_file_path = os.path.join(ROOT_DIR, 'job_descriptions', 'description.txt')\n",
    "    with open(description_file_path, 'r') as file:\n",
    "        job_description = file.read()\n",
    "\n",
    "    df_jobs = pd.DataFrame([job_description], columns=[\"raw\"])\n",
    "    df_jobs = job_info_extraction(df_jobs)\n",
    "    # print(df_jobs)\n",
    "\n",
    "    analysis_data_df = calc_similarity(df_resumes, df_jobs)\n",
    "    # print(analysis_data_df.sort_values(\"rank\", ascending=True))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hanna_pedersen ['business', 'analytics', 'business administration', 'finance', 'project management', 'data analysis', 'sql', 'artificial intelligence', 'training model', 'marketing', 'python']\n",
      "irene_abbateli ['business', 'analytics', 'data analysis', 'machine learning', 'modelling', 'business administration', 'advertising', 'python', 'marketing', 'sql', 'r', 'operations research']\n",
      "Luca_Oeztekin ['api', 'database', 'blockchain', 'business', 'html', 'sql', 'python', 'pandas', 'visualization', 'tableau', 'business intelligence', 'confluence', 'jira', 'google analytics', 'deep learning', 'data science', 'collaboration']\n",
      "Tim_Gunkel ['business', 'analytics', 'machine learning', 'business intelligence', 'marketing', 'data structure', 'hubspot', 'scalability', 'monitoring', 'python', 'sql', 'r', 'training model']\n",
      "victor_bjorsvik ['accounting', 'big data', 'communications', 'business', 'analytics', 'finance', 'data science', 'modelling', 'business administration', 'python', 'logistic regression', 'web development', 'flask', 'html', 'css', 'javascript', 'testing', 'training model', 'pandas', 'sql', 'apache spark', 'machine learning', 'tensorflow', 'keras', 'c', 'r', 'tableau']\n"
     ]
    }
   ],
   "source": [
    "for i, row in df_resumes[[\"name\", \"Skills\"]].iterrows():\n",
    "    print(row[\"name\"], row[\"Skills\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['finance',\n",
       " 'business',\n",
       " 'visualization',\n",
       " 'design',\n",
       " 'machine learning',\n",
       " 'modelling',\n",
       " 'data analysis',\n",
       " 'python',\n",
       " 'marketing',\n",
       " 'operations research',\n",
       " 'database',\n",
       " 'data quality',\n",
       " 'analytics',\n",
       " 'agile project management',\n",
       " 'training model',\n",
       " 'computer engineering',\n",
       " 'relational database',\n",
       " 'oracle',\n",
       " 'collaboration',\n",
       " 'communications',\n",
       " 'data science']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jobs.Skills[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>applicant</th>\n",
       "      <th>job_id</th>\n",
       "      <th>all-mpnet-base-v2_score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>victor_bjorsvik</td>\n",
       "      <td>0</td>\n",
       "      <td>0.738</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hanna_pedersen</td>\n",
       "      <td>0</td>\n",
       "      <td>0.718</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>irene_abbateli</td>\n",
       "      <td>0</td>\n",
       "      <td>0.706</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Luca_Oeztekin</td>\n",
       "      <td>0</td>\n",
       "      <td>0.689</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tim_Gunkel</td>\n",
       "      <td>0</td>\n",
       "      <td>0.634</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         applicant job_id  all-mpnet-base-v2_score  rank\n",
       "4  victor_bjorsvik      0                    0.738   1.0\n",
       "0   hanna_pedersen      0                    0.718   2.0\n",
       "1   irene_abbateli      0                    0.706   3.0\n",
       "2    Luca_Oeztekin      0                    0.689   4.0\n",
       "3       Tim_Gunkel      0                    0.634   5.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_data_df.sort_values(\"rank\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workproject",
   "language": "python",
   "name": "workproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
